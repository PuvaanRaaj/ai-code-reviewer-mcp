# Main LLM Provider Configuration
# Options: anthropic, openai, ollama, deepseek, huggingface, mistral
LLM_PROVIDER=anthropic

# Logging
LOG_LEVEL=INFO

# Anthropic (Claude) Configuration
ANTHROPIC_API_KEY=your-anthropic-api-key-here
ANTHROPIC_MODEL=claude-3-5-sonnet-20240620
# Other options: claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307

# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4o
# Other options: gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo

# DeepSeek Configuration
DEEPSEEK_API_KEY=your-deepseek-api-key-here
DEEPSEEK_API_BASE=https://api.deepseek.com/v1
DEEPSEEK_MODEL=deepseek-coder
# Other options: deepseek-chat, deepseek-coder-instruct

# Mistral Configuration
MISTRAL_API_KEY=your-mistral-api-key-here
MISTRAL_MODEL=mistral-large-latest
# Other options: mistral-small-latest, mistral-medium-latest

# Local Models Configuration

# Ollama Configuration
OLLAMA_MODEL=codellama:latest
# Other options: llama3:latest, mistral:latest, or any model available in Ollama

# HuggingFace Configuration
HUGGINGFACE_MODEL=bigcode/starcoder2-15b
# Other options: meta-llama/Llama-3-70b-chat-hf, mistralai/Mixtral-8x7B-Instruct-v0.1, codellama/CodeLlama-34b-Instruct-hf